Campbell2013Automatic

The perception system is composed of a Microsoft HD video camera for object detection and identification and an Acuity laser sensor.

For obstacle avoidance, the presented system has a unit to predict next positin of detected obstacles. 
They use the CPA method, assuming that detected obstacles will proceed in their current velocities, this method find the closest distance between encountering vessels at some time in the future.
Moreover, a sampling interval is determined for updating the calculated distance.
If the closest predicted distance is less than the accepta-ble range, the module advises a change in direction as
an approaching threat is confirmed.
This basic information is extracted from analysys of data captured by the perception system and them the trajectory of the obstacles are predicted usinf the following formula:
The navigation system is composed by GPS and gyrocompass.
For system evalution they performed virtual simulations using the Virtual Sailor Simulatorm\cite{Papini I. Virtual Sailor Software. SimSquared Ltd. Ship Simulator Shareware, 1999–2008. http://www.hangsim .com/vs/}.

The systems uses A* for global guidance and a modification of A*, entitled R-RA*, for local guidance.
The focus of this papers is on describing the local guidance system.

The R-RA * method consists of having the path generated by A * as the base, performing iterative changes in the path to avoid collisions. 
Path changes are performed in a local scope. 
The method is based on A *, so its implementation is based on evaluating a set of nodes in the search space and defining a closed list. 
For COLREGS-compliance, the method consider that the positions that will cause a violation of the COLREGS is marked as belonging to the closed list.
This way tha A* will not consider that nodes.
The world is locally represented in a grid representaiton.
They assume that is possible to determine other vessels heading and velocity. Thus the system uses this information for calculation of the CPA.
Every time the distance between the \ac{USV} and the CPA is shorter than the minimum acceptable distance. The local guidance system, with R-RA* is activated.

Zhuang2011Motion

Global guidance static obstacles - For global guidance they do not clearly if the system is capable of deal with static and dynamic obstacles, they only define the usage of a evolutionary path planner.
Global guidance dynamic obstacles -
Local guidance static obstacles - For local guidance they used the \ac{VO} method \cite{}.
Local guidance dynamic obstacles - 
Perception system - 
Control system - 
Navigation system - 
System evaluation - The system is evaluated through software simulation.
CORLEGS - 

For global guidance they do not clearly if the system is capable of deal with static and dynamic obstacles, they only define the usage of a evolutionary path planner.
For local guidance they used the \ac{VO} method \cite{}.
Danger situations can happen in different forms, head-on encounter, crossing, overtaking, etc... 
For identification of different situations the system is based on vision sectors with limits defined by angles related to the \ac{USV} heading.
As shown in figure \ref{fig:Zhuang2011Motion_Sectors}, the \ac{USV} heading is the 0° angle, 15° from the \ac{USV} angle defines the head-on encounter sector.
Crossing is defined 135° from \ac{USV} heading.
The system is evaluated through software simulation and the results presented, show that the local guidance system is compliant to COLREGS rules 14, and 15.

Kuwata2014Safe

Global guidance static obstacles    -
Global guidance dynamic obstacles   -
Local guidance static obstacles     - VO
Local guidance dynamic obstacles    - Detection of danger situations are done through analyses of the \ac{CPA} and vision sector but the specific angles are not clearly declared.
Perception system                   - Environemnt information about static and dynamic obstacles are captured through a perception system composed of a radar, stereo   cameras, and \ac{LIDAR}.
Control system                      -
Navigation system                   - On real-world tests the \ac{USV} state is stimated by an onboard inertial navigation system.
System evaluation                   - For system evaluation they executed real-world trials and the \ac{USV} was exposed to around 30 scenarios with single and multiple vessels encounters. 
                                        The \ac{USV} succefully acted on 24 maneuvers avoiding collision and didnt respond safely to only one situation due to a vision sensor problem.
COLREGS                             - They discuss that \ac{VO} is a intuitive way of implement COLREGS due to the fact that \ac{VO} wirk on applying constraints to the \ac{USV} possible velocity space.
    Therefore, apply COLREGS through \ac{VO} consists on applying some more constraints to the possible velocity space.
    They present the constraints used to implement COLREGS rules 13 (overtaking), 14 (head-on), and 15 (crossing).

Kuwata \etal~\cite{Kuwata2014Safe} present a COLREGS-compliant local guidance system based on \ac{VO} capable of address static and dynamic obstacles.
Detection of danger situations is done through analyses of the \ac{CPA} and vision sector but the specific angles are not clearly declared.
Environemnt information about static and dynamic obstacles are captured through a perception system composed of a radar, stereo cameras, and \ac{LIDAR}.
On real-world tests the \ac{USV} state is stimated by an onboard inertial navigation system.
They discuss that \ac{VO} is a intuitive way of implement COLREGS due to the fact that \ac{VO} work on applying constraints to the \ac{USV} possible velocity space.
Therefore, apply COLREGS through \ac{VO} consists on applying some more constraints to the possible velocity space.
They present the constraints used to implement COLREGS rules 13 (overtaking), 14 (head-on), and 15 (crossing).
For system evaluation they executed real-world trials and the \ac{USV} was exposed to around 30 scenarios with single and multiple vessels encounters. 
The \ac{USV} succefully acted on 24 maneuvers avoiding collision and didnt respond safely to only one situation due to a vision sensor problem.
